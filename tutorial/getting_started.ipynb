{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "44518e6b",
   "metadata": {},
   "source": [
    "# Getting Started\n",
    "\n",
    "This notebook goes through the basic usage of the LLM endpoints provided by LLM Operator.\n",
    "\n",
    "## Prerequisites\n",
    "\n",
    "- LLM Operator needs to be installed. Please visit\n",
    "  [the documentation site](https://llm-operator.readthedocs.io/en/latest/index.html) for the installation procedure.\n",
    "- This notebook uses [the OpenAI Python library](https://github.com/openai/openai-python). Please run\n",
    "  `pip install openai` to install it.\n",
    "- This notebook requires an API key.\n",
    "\n",
    "## Set up a Client\n",
    "\n",
    "The first step is to create an `OpenAI` client. You need to set `base_url` and `api_key`\n",
    "based on your configuration.\n",
    "\n",
    "The value of `base_url` points to the address of the LLM Operator API endpoint.\n",
    "For example, the `base_rul` is set to `http://localhost:8080/v1` if you're accessing\n",
    "the endpoint running at your localhost with port 8080."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4780217",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "\n",
    "client = OpenAI(\n",
    "  base_url=\"http://localhost:8080/v1\",\n",
    "  api_key=\"eyJhbGciOiJSUzI1NiIsImtpZCI6ImY4NjgyNjE3MjAyNmM1Y2FiOTNmMWEzNWI1MzE4Yzk0MGUzYWNmNTAifQ.eyJpc3MiOiJodHRwOi8va29uZy1rb25nLXByb3h5LmtvbmcvdjEvZGV4Iiwic3ViIjoiQ2lRd09HRTROamcwWWkxa1lqZzRMVFJpTnpNdE9UQmhPUzB6WTJReE5qWXhaalUwTmpZU0JXeHZZMkZzIiwiYXVkIjoibGxtLW9wZXJhdG9yIiwiZXhwIjoxNzE0Nzk4OTU2LCJpYXQiOjE3MTQ3MTI1NTYsImF0X2hhc2giOiJVS1lzelBGVkt5VWVkQkoyX2R5Z3NBIiwiZW1haWwiOiJhZG1pbkBleGFtcGxlLmNvbSIsImVtYWlsX3ZlcmlmaWVkIjp0cnVlfQ.jnp4kAx3_RuygiTkHuv2kbn1Ca9l8opoZ0ZwnP5UbvGvhMZzmocwNKqLhPm4_Di86RR_2BwgVw5mSz8zw5zIzU2lUH1KJXwYiw8npRuyTx430jVprO68cAvfxqbkwvFH-VS9A4Dc6q6lTb2qAbxK4Hg6tKqnVr1NHFquBRdKBpdLuQcmjgmf02yIfZOShANCzK_GFa3u282cVsISoltCeEEjhGfeWCZJ1S-W4kimhFxx264K2PgoD_rzGMh2yjOu4-WwYv8BLSYaihPRRGSWpwhDryyFj37XCP403yJeTdI1DtDXb2mHeRe0ANO3bDy7hz26LYg8_j7FCqLHpDf-oA\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd55b8ed",
   "metadata": {},
   "source": [
    "## Find Installed LLM Models\n",
    "\n",
    "Let's first find LLM models that have been installed. You can use\n",
    "these models for chat completion, fine-tuning, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44be63ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "models = client.models.list()\n",
    "print(sorted(list(map(lambda m: m.id, models.data))))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6644ef71",
   "metadata": {},
   "source": [
    "If you install LLM Operator with the default configuration, you should see `google-gemma-2b-it` and `google-gemma-2b-it-q4`.\n",
    "\n",
    "Let's then pick up the first model and use for the rest of the tutorial."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a262567",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_id = 'google-gemma-2b-it'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09714220",
   "metadata": {},
   "source": [
    "## Run Chat Completion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12c3433b",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "completion = client.chat.completions.create(\n",
    "  model=model_id,\n",
    "  messages=[\n",
    "    {\"role\": \"user\", \"content\": \"What is k8s?\"}\n",
    "  ]\n",
    ")\n",
    "print(completion.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbfa2865",
   "metadata": {},
   "source": [
    "## Run a fine-tuning Job\n",
    "\n",
    "Next, let's run a fine-tuning model.\n",
    "\n",
    "We need training data. We can get sample one from [the OpenAI page](https://platform.openai.com/docs/guides/fine-tuning/preparing-your-dataset) and\n",
    "save it locally."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c360a8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_filename = \"my_training_data.jsonl\"\n",
    "\n",
    "data = [\n",
    "  \"\"\"{\"messages\": [{\"role\": \"user\", \"content\": \"What's the capital of France?\"}, {\"role\": \"assistant\", \"content\": \"Paris, as if everyone doesn't know that already.\"}]}\"\"\",\n",
    "  \"\"\"{\"messages\": [{\"role\": \"user\", \"content\": \"Who wrote 'Romeo and Juliet'?\"}, {\"role\": \"assistant\", \"content\": \"Oh, just some guy named William Shakespeare. Ever heard of him?\"}]}\"\"\",\n",
    "  \"\"\"{\"messages\": [{\"role\": \"user\", \"content\": \"How far is the Moon from Earth?\"}, {\"role\": \"assistant\", \"content\": \"Around 384,400 kilometers. Give or take a few, like that really matters.\"}]}\"\"\",\n",
    "]\n",
    "\n",
    "with open(training_filename, \"w\") as fp:\n",
    "  fp.write('\\n'.join(data))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3385672",
   "metadata": {},
   "source": [
    "Next upload the file to the system."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea2ebe04",
   "metadata": {},
   "outputs": [],
   "source": [
    "file = client.files.create(\n",
    "  file=open(training_filename, \"rb\"),\n",
    "  purpose='fine-tune',\n",
    ")\n",
    "print('Uploaded file. ID=%s' % file.id)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9f3e757",
   "metadata": {},
   "source": [
    "You can verify the update succeeded."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "386d4926",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(client.files.list().data[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a63dd2e",
   "metadata": {},
   "source": [
    "Then start a fine-tuning job."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "432231ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "resp = client.fine_tuning.jobs.create(\n",
    "  model=\"google-gemma-2b-it\",\n",
    "  suffix='fine-tuning',\n",
    "  training_file=file.id,\n",
    ")\n",
    "print('Created job. ID=%s' % resp.id)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bcfc624",
   "metadata": {},
   "source": [
    "A pod is created in your Kubernetes cluster. You can check the progress of the fine-tuning job from its log.\n",
    "\n",
    "Once the job completes, you can check the generated models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b62e414",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(client.fine_tuning.jobs.list().data[0].fine_tuned_model)\n",
    "models = list(map(lambda m: m.id, client.models.list().data))\n",
    "print(models)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8374467",
   "metadata": {},
   "source": [
    "Then you can get the model ID and use that for the chat completion request."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97e40c5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_id = list(filter(lambda m: 'fine-tuning' in m, models))[0][3:]\n",
    "print(model_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbd708e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "completion = client.chat.completions.create(\n",
    "  model=model_id,\n",
    "  messages=[\n",
    "    {\"role\": \"user\", \"content\": \"What is k8s?\"}\n",
    "  ]\n",
    ")\n",
    "print(completion.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51c89290",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(client.fine_tuning.jobs.list().data[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c053e13b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
