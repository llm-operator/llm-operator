# This values file is for a dev env where kong, minio, and postgres are installed in the same k8s cluster.

global:
  llmOperatorBaseUrl: http://kong-proxy.kong/v1/

  database:
    host: postgres.postgres
    port: 5432
    username: ps_user
    ssl:
      mode: disable

  databaseSecret:
    name: postgres
    key: password

  objectStore:
    s3:
      endpointUrl: http://minio.minio:9000
      region: dummy
      bucket: llm-operator

  awsSecret:
    name: aws
    accessKeyIdKey: accessKeyId
    secretAccessKeyKey: secretAccessKey

  ingress:
    ingressClassName: kong

  auth:
    # This works when Kong is used as an ingress controller and it
    # is deployed to the kong namespace.
    oidcIssuerUrl: http://kong-proxy.kong/v1/dex

  worker:
    registrationKeySecret:
      name: default-cluster-registration-key
      key: key

inference-manager-engine:
  commandName: alpha
  runtime:
    name: ollama
    defaultResources:
      # Do not allocate GPU to inference-manager-engine since g5.4xlarge has only one GPU,
      # and it is needed for the fine-tuning job
      #
      # TODO(kenji): Enable GPU sharing
      nvidia.com/gpu: 0
  resources:
    limits:
      nvidia.com/gpu: 0
  autoscaling:
    enableKeda: false
    scaledobject:
      minReplicaCount: 1
      maxReplicaCount: 2
      prometheusServerAddr: http://prometheus-server.monitoring:80
  preloadedModelIds:
  - google/gemma-2b-it-q4

inference-manager-server:
  service:
    annotations:
      konghq.com/connect-timeout: "360000"
      konghq.com/read-timeout: "360000"
      konghq.com/write-timeout: "360000"

job-manager-dispatcher:
  notebook:
    ingressClassName: kong-internal

model-manager-loader:
  baseModels:
  - google/gemma-2b-it
  - google/gemma-2b-it-q4

session-manager-agent:
  ingressControllerAddress: kong-internal-proxy.kong-internal
  ingressControllerPort: 80
