# This values file is for a dev env where kong, minio, and postgres are installed in the same k8s cluster.

global:
  database:
    host: postgres.postgres
    port: 5432
    username: ps_user
    ssl:
      mode: disable

  databaseSecret:
    name: postgres
    key: password

  objectStore:
    s3:
      endpointUrl: http://minio.minio:9000
      region: dummy
      bucket: llm-operator

  awsSecret:
    name: aws
    accessKeyIdKey: accessKeyId
    secretAccessKeyKey: secretAccessKey

  ingress:
    ingressClassName: kong

  auth:
    # This works when Kong is used as an ingress controller and it
    # is deployed to the kong namespace.
    oidcIssuerUrl: http://kong-proxy.kong/v1/dex

inference-manager-engine:
  # Do not allocate GPU to inference-manager-engine since g5.4xlarge has only one GPU,
  # and it is needed for the fine-tuning job
  #
  # TODO(kenji): Enable GPU sharing
  resources:
    gpu: 0

inference-manager-server:
  service:
    annotations:
      konghq.com/connect-timeout: "360000"
      konghq.com/read-timeout: "360000"
      konghq.com/write-timeout: "360000"

model-manager-loader:
  baseModels:
  - google-gemma-2b-it
  - google/gemma-2b-it-q4
