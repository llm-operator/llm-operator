tags:
  control-plane: false

global:
  llmOperatorBaseUrl: https://api.llmo.cloudnatix.com/v1

  auth:
    oidcIssuerUrl: https://api.llmo.cloudnatix.com/v1/dex

  worker:
    registrationKeySecret:
      name: cluster-registration-key
      key: regKey
    tls:
      enable: true
    controlPlaneAddr: api.llmo.cloudnatix.com:443

  objectStore:
    s3:
      # TODO(kenji): Use HTTPS instead of HTTP.
      endpointUrl: http://api.llmo.cloudnatix.com:9000


inference-manager-engine:
  logLevel: 1
  inferenceManagerServerWorkerServiceAddr: api.llmo.cloudnatix.com:445
  model:
    default:
      runtimeName: vllm
      resources:
        limits:
          nvidia.com/gpu: 1
    overrides:
      deepseek-ai/deepseek-coder-6.7b-base-awq:
        preloaded: false
        contextlength: 16384
      google/gemma-2b-it-q4:
        runtimeName: ollama
        preloaded: true
        resources:
          limits:
            nvidia.com/gpu: 0
      intfloat/e5-mistral-7b-instruct:
        preloaded: false
      meta-llama/Meta-Llama-3.1-70B-Instruct-awq:
        preloaded: true
        contextlength: 16384
        resourecs:
          limits:
            nvidia.com/gpu: 4
      sentence-transformers/all-MiniLM-L6-v2-f16:
        runtimeName: ollama
        preloaded: true
        resources:
          limits:
            nvidia.com/gpu: 0
  autoscaling:
    enableKeda: false


model-manager-loader:
  baseModels:
  - deepseek-ai/deepseek-coder-6.7b-base-awq
  - google/gemma-2b-it-q4
  - intfloat/e5-mistral-7b-instruct
  - meta-llama/Meta-Llama-3.1-70B-Instruct-awq
  - sentence-transformers/all-MiniLM-L6-v2-f16


session-manager-agent:
  proxy:
    baseUrl: https://api.llmo.cloudnatix.com:444
