global:
  llmOperatorBaseUrl: https://api.llmo.cloudnatix.com/v1

  auth:
    oidcIssuerUrl: https://api.llmo.cloudnatix.com/v1/dex

  worker:
    registrationKeySecret:
      name: cluster-registration-key
      key: regKey
    tls:
      enable: true
    controlPlaneAddr: api.llmo.cloudnatix.com:443

  objectStore:
    s3:
      # TODO(kenji): Use HTTPS instead of HTTP.
      endpointUrl: http://api.llmo.cloudnatix.com:9000

inference-manager-engine:
  inferenceManagerServerWorkerServiceAddr: api.llmo.cloudnatix.com:445
  # TODO(kenji): Revisit. This prevents fine-tuning jobs from running on a single GPU instance.
  resources:
    gpu: 1
  autoscaling:
    enableKeda: false

model-manager-loader:
  baseModels:
  - google/gemma-2b-it
  - google/gemma-2b-it-q4
  - meta-llama/Meta-Llama-3.1-8B-Instruct
  - meta-llama/Meta-Llama-3.1-8B-Instruct-q4

session-manager-agent:
  proxy:
    baseUrl: https://api.llmo.cloudnatix.com:444
